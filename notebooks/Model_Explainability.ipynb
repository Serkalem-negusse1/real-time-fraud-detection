{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explainability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, SimpleRNN, LSTM\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Git_repo\\real-time-fraud-detection\\fdvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import tqdm\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "creditcard_df = pd.read_csv('E:/Git_repo/real-time-fraud-detection/data/creditcard_preprocessed.csv')\n",
    "fraud_df = pd.read_csv('E:/Git_repo/real-time-fraud-detection/data/Processed_Fraud_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in creditcard_preprocessed.csv:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Processed_Fraud_Data.csv:\n",
      "user_id                    0\n",
      "signup_time                0\n",
      "purchase_time              0\n",
      "purchase_value             0\n",
      "device_id                  0\n",
      "source                     0\n",
      "browser                    0\n",
      "sex                        0\n",
      "age                        0\n",
      "ip_address            151112\n",
      "class                      0\n",
      "signup_hour                0\n",
      "signup_day                 0\n",
      "purchase_hour              0\n",
      "purchase_day               0\n",
      "country                    0\n",
      "log_purchase_value         0\n",
      "region                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#### Check for missing values\n",
    "print(\"Missing values in creditcard_preprocessed.csv:\")\n",
    "print(creditcard_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Processed_Fraud_Data.csv:\")\n",
    "print(fraud_df.isnull().sum())\n",
    "\n",
    "#####creditcard_df.drop(columns=['ip_address'], inplace=True)\n",
    "fraud_df.drop(columns=['ip_address'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151112, 17), (284807, 31))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.shape, creditcard_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
       "        'device_id', 'source', 'browser', 'sex', 'age', 'class', 'signup_hour',\n",
       "        'signup_day', 'purchase_hour', 'purchase_day', 'country',\n",
       "        'log_purchase_value', 'region'],\n",
       "       dtype='object'),\n",
       " Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "        'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "        'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "        'Class'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.columns, creditcard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([136961,  14151]))\n",
      "(array([0, 1]), array([284315,    492]))\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "\n",
    "# Prepare data for the model (e-commerce)\n",
    "X1 = fraud_df.drop(columns=['class'])\n",
    "X2 = creditcard_df.drop(columns=['Class'])\n",
    "\n",
    "y1 = fraud_df['class']\n",
    "y2 = creditcard_df['Class']\n",
    "\n",
    "print(np.unique(y1, return_counts=True))\n",
    "print(np.unique(y2, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
