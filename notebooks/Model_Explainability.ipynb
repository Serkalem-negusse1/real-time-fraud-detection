{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explainability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, SimpleRNN, LSTM\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Git_repo\\real-time-fraud-detection\\fdvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import tqdm\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "creditcard_df = pd.read_csv('E:/Git_repo/real-time-fraud-detection/data/creditcard_preprocessed.csv')\n",
    "fraud_df = pd.read_csv('E:/Git_repo/real-time-fraud-detection/data/Processed_Fraud_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in creditcard_preprocessed.csv:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Processed_Fraud_Data.csv:\n",
      "user_id                    0\n",
      "signup_time                0\n",
      "purchase_time              0\n",
      "purchase_value             0\n",
      "device_id                  0\n",
      "source                     0\n",
      "browser                    0\n",
      "sex                        0\n",
      "age                        0\n",
      "ip_address            151112\n",
      "class                      0\n",
      "signup_hour                0\n",
      "signup_day                 0\n",
      "purchase_hour              0\n",
      "purchase_day               0\n",
      "country                    0\n",
      "log_purchase_value         0\n",
      "region                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#### Check for missing values\n",
    "print(\"Missing values in creditcard_preprocessed.csv:\")\n",
    "print(creditcard_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Processed_Fraud_Data.csv:\")\n",
    "print(fraud_df.isnull().sum())\n",
    "\n",
    "#####creditcard_df.drop(columns=['ip_address'], inplace=True)\n",
    "fraud_df.drop(columns=['ip_address'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target separation\n",
    "def prepare_data(df, target_col):\n",
    "    # Handle datetime columns (e.g., signup_time, purchase_time)\n",
    "    date_columns = ['signup_time', 'purchase_time']  # Replace with the actual datetime columns\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            # Convert to datetime format\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            # Extract useful time-related features (year, month, day, hour, etc.)\n",
    "            df[f'{col}_year'] = df[col].dt.year\n",
    "            df[f'{col}_month'] = df[col].dt.month\n",
    "            df[f'{col}_day'] = df[col].dt.day\n",
    "            df[f'{col}_hour'] = df[col].dt.hour\n",
    "            df[f'{col}_minute'] = df[col].dt.minute\n",
    "            df[f'{col}_second'] = df[col].dt.second\n",
    "            # Drop the original datetime column\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Handle categorical columns (e.g., sex, browser, country, source, device_id)\n",
    "    categorical_columns = ['sex', 'browser', 'country', 'source', 'device_id', 'region']  # Add more if needed\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151112, 17), (284807, 31))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.shape, creditcard_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
       "        'device_id', 'source', 'browser', 'sex', 'age', 'class', 'signup_hour',\n",
       "        'signup_day', 'purchase_hour', 'purchase_day', 'country',\n",
       "        'log_purchase_value', 'region'],\n",
       "       dtype='object'),\n",
       " Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "        'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "        'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "        'Class'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.columns, creditcard_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([284315,    492]))\n",
      "(array([0, 1]), array([136961,  14151]))\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "\n",
    "X_credit, y_credit = prepare_data(creditcard_df, 'Class')\n",
    "X_fraud, y_fraud = prepare_data(fraud_df, 'class')\n",
    "print(np.unique(y_credit, return_counts=True))\n",
    "print(np.unique(y_fraud, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "#X1 = fraud_df.drop(columns=['class'])\n",
    "#X2 = creditcard_df.drop(columns=['Class'])\n",
    "\n",
    "#y1 = fraud_df['class']\n",
    "#y2 = creditcard_df['Class']\n",
    "\n",
    "#print(np.unique(y1, return_counts=True))\n",
    "#print(np.unique(y2, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95    109588\n",
      "           1       1.00      0.00      0.00     11301\n",
      "\n",
      "    accuracy                           0.91    120889\n",
      "   macro avg       0.95      0.50      0.48    120889\n",
      "weighted avg       0.92      0.91      0.86    120889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the MultiLayer Perceptron Model\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=200, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp1.fit(X_train_fraud, y_train_fraud)\n",
    "\n",
    "# Predictions\n",
    "y_pred_mlp1 = mlp1.predict(X_train_fraud)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_train_fraud, y_pred_mlp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_df shape: (151112, 27)\n",
      "X_fraud shape before dropping: (151112, 26)\n",
      "y_fraud shape: (151112,)\n"
     ]
    }
   ],
   "source": [
    "print(\"fraud_df shape:\", fraud_df.shape)  # Should be (284,807, X)\n",
    "print(\"X_fraud shape before dropping:\", fraud_df.drop(columns=['class']).shape)\n",
    "print(\"y_fraud shape:\", fraud_df[\"class\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed X_fraud shape: (151112, 26)\n",
      "Fixed y_fraud shape: (151112,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure X_fraud and y_fraud are derived from the same dataset\n",
    "if \"class\" in fraud_df.columns:\n",
    "    # Drop rows with missing values in features\n",
    "    X_fraud = fraud_df.drop(columns=[\"class\"]).copy()\n",
    "    y_fraud = fraud_df[\"class\"].copy()\n",
    "\n",
    "    # Check again\n",
    "    print(\"Fixed X_fraud shape:\", X_fraud.shape)\n",
    "    print(\"Fixed y_fraud shape:\", y_fraud.shape)\n",
    "else:\n",
    "    raise ValueError(\"The dataset does not contain a 'Class' column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Git_repo\\real-time-fraud-detection\\fdvenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9293 - loss: 0.2338 - val_accuracy: 0.9554 - val_loss: 0.1819\n",
      "Epoch 2/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1795 - val_accuracy: 0.9554 - val_loss: 0.1813\n",
      "Epoch 3/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.1793 - val_accuracy: 0.9559 - val_loss: 0.1822\n",
      "Epoch 4/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.1779 - val_accuracy: 0.9562 - val_loss: 0.1787\n",
      "Epoch 5/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.1780 - val_accuracy: 0.9539 - val_loss: 0.1838\n",
      "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     27393\n",
      "           1       0.94      0.53      0.68      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.94      0.76      0.82     30223\n",
      "weighted avg       0.95      0.95      0.95     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_lstm = X_train_fraud.values.reshape(-1, X_train_fraud.shape[1], 1)\n",
    "X_test_lstm = X_test_fraud.values.reshape(-1, X_test_fraud.shape[1], 1)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_fraud.shape[1], 1)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_lstm, y_train_fraud, epochs=5, batch_size=32, validation_split=0.2) #validation_data=(X_test_fraud, y_test_fraud))\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_fraud, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Git_repo\\real-time-fraud-detection\\fdvenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.2373 - val_accuracy: 0.9532 - val_loss: 0.1961\n",
      "Epoch 2/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1922 - val_accuracy: 0.9539 - val_loss: 0.1865\n",
      "Epoch 3/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1871 - val_accuracy: 0.9538 - val_loss: 0.1875\n",
      "Epoch 4/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.1863 - val_accuracy: 0.9545 - val_loss: 0.1876\n",
      "Epoch 5/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1908 - val_accuracy: 0.9537 - val_loss: 0.1868\n",
      "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     27393\n",
      "           1       0.92      0.53      0.67      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.94      0.76      0.82     30223\n",
      "weighted avg       0.95      0.95      0.95     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_rnn = X_train_fraud.values.reshape(-1, X_train_fraud.shape[1], 1)\n",
    "X_test_rnn = X_test_fraud.values.reshape(-1, X_test_fraud.shape[1], 1)\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(64, input_shape=(X_train_fraud.shape[1], 1)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.fit(X_train_fraud, y_train_fraud, epochs=5, batch_size=32, validation_split=0.2) #validation_data=(X_test_fraud, y_test_fraud))\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_fraud, y_pred_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Git_repo\\real-time-fraud-detection\\fdvenv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 57.1778 - val_accuracy: 0.9076 - val_loss: 16.8879\n",
      "Epoch 2/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 10.2398 - val_accuracy: 0.9082 - val_loss: 6.1111\n",
      "Epoch 3/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 3.5147 - val_accuracy: 0.7638 - val_loss: 1.2308\n",
      "Epoch 4/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 1.6958 - val_accuracy: 0.9243 - val_loss: 0.7335\n",
      "Epoch 5/5\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.6348 - val_accuracy: 0.9432 - val_loss: 0.2322\n",
      "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     27393\n",
      "           1       0.87      0.45      0.59      2830\n",
      "\n",
      "    accuracy                           0.94     30223\n",
      "   macro avg       0.91      0.72      0.78     30223\n",
      "weighted avg       0.94      0.94      0.93     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense \n",
    "\n",
    "X_train_cnn = X_train_fraud.values.reshape(-1, X_train_fraud.shape[1], 1)\n",
    "X_test_cnn = X_test_fraud.values.reshape(-1, X_test_fraud.shape[1], 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_fraud.shape[1], 1)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_fraud, y_train_fraud, epochs=5, batch_size=32, validation_split=0.2) #validation_data=(X_test_fraud, y_test_fraud))\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_pred_cnn = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_fraud, y_pred_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explanation for fraud dataset using KernelExplainer\n",
    "explainer1 = shap.Explainer(mlp1, X_train_fraud)  # Ensure X_train1 is used as background\n",
    "shap_values1 = explainer1(X_test_fraud)  # Ensure X_test1 has the same shape as X_train1\n",
    "\n",
    "# Plot summary plot for fraud data\n",
    "shap.summary_plot(shap_values1, X_test_fraud, feature_names=X_fraud.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## individual predictions\n",
    "\n",
    "# Choose a sample instance\n",
    "sample_idx = 5\n",
    "shap.force_plot(explainer_lstm.expected_value[0], shap_values_lstm[0][sample_idx], X_test_fraud[sample_idx].reshape(-1), feature_names=creditcard_df.drop(columns=[\"class\"]).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data back for SHAP explanation\n",
    "\n",
    "X_test_lstm_flat = X_test_lstm.reshape(X_test_fraud.shape)\n",
    "\n",
    "explainer = shap.KernelExplainer(lstm_model.predict, X_test_lstm_flat)\n",
    "shap_values = explainer.shap_values(X_test_lstm_flat)\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_values[0], X_test_lstm_flat, feature_names=X_train_fraud.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local interpretability with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LIME explainer\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_fraud.reshape(X_train_fraud.shape[0], -1), \n",
    "    feature_names=creditcard_df.drop(columns=[\"class\"]).columns, \n",
    "    class_names=[\"Not Fraud\", \"Fraud\"], \n",
    "    mode=\"classification\"\n",
    ")\n",
    "\n",
    "# Explain a single prediction for LSTM\n",
    "sample_idx = 5\n",
    "exp = lime_explainer.explain_instance(X_test_fraud[sample_idx].reshape(-1), lstm_model.predict, num_features=5)\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP dependence plot for a key feature (purchase_value)\n",
    "shap.dependence_plot(\"purchase_value\", shap_values_lstm[0], X_test_fraud.reshape(X_test_fraud.shape[0], -1), feature_names=creditcard_df.drop(columns=[\"class\"]).columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
